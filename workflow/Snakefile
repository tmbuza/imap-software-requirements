from snakemake.utils import min_version

min_version("6.10.0")

# Configuration file containing all user-specified settings
configfile: "config/config.yaml"

mothurSamples = list(set(glob_wildcards(os.path.join('data/mothur/reads/', '{sample}_{readNum, R[12]}_001.fastq.gz')).sample))

sraSamples = list(set(glob_wildcards(os.path.join('data/reads/', '{sample}_{sraNum, [12]}.fastq.gz')).sample))


import os
import csv
import pandas as pd

# RUNINFO="data/metadata"
METADATA=pd.read_csv('data/metadata/SraRunTable.csv').loc[0:3]
ACCESSIONS=METADATA['Run'].tolist() # Specify the column containing the accession, in this demo is Run
# OUTDIR="data/reads" 
# TESTDIR="data/test"

# if not os.path.exists(OUTDIR):
#    os.makedirs(OUTDIR)

# if not os.path.exists(TESTDIR):
#    os.makedirs(TESTDIR)

# Master rule for controlling workflow.
rule all:
    input:
        "index.html",
        # "data/metadata/sra_accessions.txt",
        # "images/project_tree.txt",
        # "data/metadata/metadata.csv",
        # "data/metadata/ibd.csv",
        # "results/read_size_asce.csv",
        # "results/read_size_desc.csv",
        # "images/variable_freq.png",
        # "images/bush_variable_freq.svg",
        # "images/ibd_variable_freq.svg",
        # "images/sample_gps.png",
        # "images/smkreport/screenshot.png", 
        # expand("data/metadata/runinfo_{bioproject}.csv", bioproject=config["bioproject"]),
        # expand("data/metadata/acc_{bioproject}.txt", bioproject=config["bioproject"]),
        # expand("data/metadata/{bioproject}.csv", bioproject=config["BioProject"]),
        expand("data/reads/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
        expand("data/test/{accession}_{sraNum}_sub.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),

        # expand("data/test/{accession}_1.fastq", accession=ACCESSIONS),
        # expand("data/test/{accession}_2.fastq", accession=ACCESSIONS),
        # # "data/metadata/mothur_mapping_file.tsv",
        # # "data/metadata/mothur_design_file.tsv",
        # "data/mothur/references/silva.v4.align",
        # "data/mothur/references/trainset16_022016.pds.fasta",
        # "data/mothur/references/trainset16_022016.pds.tax",
        # "data/mothur/references/zymo.mock.16S.v4.fasta",
        # # "images/smkreport/screenshot.png",  


# Download SRA metadata
rule fetch_sra_metadata:
    output:
        runinfo=expand("data/metadata/runinfo_{bioproject}.csv", bioproject=config["bioproject"]),
        runacc=expand("data/metadata/acc_{bioproject}.txt", bioproject=config["bioproject"]),
    shell:
         "bash workflow/scripts/fetch_sra_metadata.sh"

        

# Process SRA metadata
rule process_local_metadata:
    input:
        runacc=expand("data/metadata/acc_{bioproject}.txt", bioproject=config["bioproject"]),
    output:
        metadata="data/metadata/metadata.csv",
    script:
        "scripts/process_sra_metadata.R"
        

# Get variable barplot
rule get_variable_freq:
    input:
        "data/metadata/metadata.csv"
    output:
        png="images/variable_freq.png",
        svg="images/variable_freq.svg"
    script:
        "scripts/plot_var_freq.R"


# Get read size
rule explore_read_size:
    input:
        "data/metadata/metadata.csv"
    output:
        asce="results/read_size_asce.csv",
        desc="results/read_size_desc.csv"
    script:
        "scripts/explore_read_size.R"
      

# Get sample location 
rule plot_sample_location:
    input:
        "data/metadata/metadata.csv"
    output:
        map="images/sample_gps.png"
    script:
        "scripts/get_sample_gps.R"


# Get SRA accessions, the first column of metadata
rule get_sra_accessions:
    input:
        sra_acc="data/metadata/metadata.csv",
    output:
        sra_acc="data/metadata/sra_accessions.txt",
    script:
        "scripts/get_sra_accessions.py"


# Dowload the SRA RUN reads
rule download_sra_reads: 
    input:
        rules.get_sra_accessions.output,
        rules.fetch_sra_metadata.output
    output:
        "data/reads/{accession}_1.fastq",
        "data/reads/{accession}_2.fastq"
    params:
        download_folder="data/reads",
        subset_folder="data/test",
    threads: 1
    shell:
        """
        fasterq-dump \
        --split-3 --force \
        --skip-technical {wildcards.accession} \
        --outdir {params.download_folder} \
        --temp {params.subset_folder} \
        --threads {threads}
        """

# Subset a test data
rule seqkit_subset_fastq:
    input:
        expand("data/reads/{accession}_1.fastq", accession=ACCESSIONS),
        expand("data/reads/{accession}_2.fastq", accession=ACCESSIONS),
    output:
        "data/test/{accession}_1_sub.fastq",
        "data/test/{accession}_2_sub.fastq",
    threads: 1
    shell:
        """
        bash workflow/scripts/subset_fastq.sh
        """


rule seqkit_simple_stats:
    input:
        script="workflow/scripts/seqkit_stat_1.sh",
        rawreads=expand("data/reads/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
    output:
        seqkit1="results/stats1/seqkit_stats.txt",
    threads: 1
    shell:
      "bash {input.script}"


rule mothur_mapping_file:
    input:
        stats1="results/stats1/seqkit_stats.txt"
    output:
        files="data/metadata/mothur_mapping_file.tsv",
    threads: 1
    script:
      "scripts/mothur_mapping_file.R"


rule mothur_design_file:
    input:
        files="data/metadata/mothur_mapping_file.tsv",
    output:
        files="data/metadata/mothur_design_file.tsv",
    threads: 1
    script:
      "scripts/mothur_design_file.R"

# # Downloading and formatting SILVA and RDP reference databases. The v4 region is extracted from 
# # SILVA database for use as reference alignment.
# rule mothur_references:
# 	input:
# 		script="workflow/scripts/mothurReferences.sh"
# 	output:
# 		silvaV4="data/mothur/references/silva.v4.align",
# 		rdpFasta="data/mothur/references/trainset16_022016.pds.fasta",
# 		rdpTax="data/mothur/references/trainset16_022016.pds.tax"
# 	conda:
# 		"envs/mothur.yaml"
# 	shell:
# 		"bash {input.script}"


# # Downloading the Zymo mock sequence files and extracting v4 region for error estimation.
# rule mothur_zymo_mock:
# 	input:
# 		script="workflow/scripts/mothurMock.sh",
# 		silvaV4="data/mothur/references/silva.v4.align",
# 	output:
# 		mockV4="data/mothur/references/zymo.mock.16S.v4.fasta"
# 	conda:
# 		"envs/mothur.yaml"
# 	shell:
# 		"bash {input.script}"


# Get directory tree
# rule get_project_tree:
# 	output:
# 		tree="images/project_tree.txt"
# 	shell:
# 		"tree -d . >{output}"

# rule project_tree:
#     output:
#         tree="images/project_tree.txt"
#     shell:
#         """
#         bash workflow/scripts/tree.sh
#         """

# rule gather_bioinfo_resources:
#     shell:
#         """
#         bash workflow/scripts/get_bioinfo_resources.sh
#         """


# # Get rule graphs
# rule dot_rulegraph:
#     output:
#         "dags/rulegraph.svg",
#     shell:
#         """
#         bash workflow/scripts/rules_dag.sh
#         """

# # Get smk html report
# rule snakemake_html_report:
#     shell:
#         """
#         bash workflow/scripts/smk_html_report.sh
#         """

rule deploy_to_github_pages:
    input:
        script="workflow/scripts/render.R",
        rmd="index.Rmd",
        rulegraph="dags/rulegraph.svg",
        dag="images/variable_freq.svg",
        map="images/sample_gps.png",
        # html2png="images/smkreport/screenshot.png",
        # tree="images/project_tree.txt",
        asce="results/read_size_asce.csv",
        desc="results/read_size_desc.csv",
        mapfiles="data/metadata/mothur_mapping_file.tsv",
        design="data/metadata/mothur_design_file.tsv"
    output:
        doc="index.html",
    shell:
        """
        R -e "library(rmarkdown); render('{input.rmd}')"
        """
